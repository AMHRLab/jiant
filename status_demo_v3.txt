06/27 03:40:38 PM: fastText library not found!
06/27 03:40:39 PM: Parsed args: 
{
  "batch_size": 16,
  "bidirectional": 1,
  "bpp_base": 1,
  "char_embs": 0,
  "char_filter_sizes": "2,3,4,5",
  "classifier": "mlp",
  "classifier_dropout": 0.2,
  "classifier_hid_dim": 32,
  "cove": 0,
  "cuda": 0,
  "d_char": 100,
  "d_ff": 2048,
  "d_hid": 128,
  "d_hid_dec": 300,
  "d_proj": 64,
  "d_word": 300,
  "data_dir": "/usr/share/jsalt/glue_data",
  "do_eval": 1,
  "do_train": 1,
  "dropout": 0.2,
  "dropout_embs": 0.2,
  "elmo": 1,
  "elmo_chars_only": 1,
  "eval_max_vals": 10,
  "eval_tasks": "mrpc",
  "eval_val_interval": 10,
  "exp_dir": "/home/raghu1991_p_gmail_com/exp/jiant-demo_v3/",
  "exp_name": "jiant-demo_v3",
  "fastText": 0,
  "fastText_model_file": ".",
  "force_load_epoch": -1,
  "load_eval_checkpoint": "none",
  "load_model": 0,
  "log_file": "log.log",
  "lr": 0.001,
  "lr_decay_factor": 0.5,
  "max_char_v_size": 250,
  "max_grad_norm": 5.0,
  "max_seq_len": 10,
  "max_vals": 10,
  "max_word_v_size": 5000,
  "min_lr": 1e-06,
  "n_char_filters": 100,
  "n_epochs": 10000,
  "n_heads": 8,
  "n_layers_dec": 1,
  "n_layers_enc": 1,
  "n_layers_highway": 0,
  "no_tqdm": 1,
  "optimizer": "adam",
  "pair_enc": "simple",
  "patience": 10,
  "preproc_file": "preproc.pkl",
  "random_seed": 42,
  "reload_indexing": 0,
  "reload_tasks": 0,
  "reload_vocab": 1,
  "run_dir": "/home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst",
  "run_name": "sst",
  "scaling_method": "none",
  "scheduler_threshold": 0.0001,
  "sent_combine_method": "max",
  "sent_enc": "rnn",
  "shared_optimizer": 1,
  "shared_pair_enc": 1,
  "skip_embs": 1,
  "task_classifier_dropout": 0.2,
  "task_classifier_hid_dim": 256,
  "task_lr": 0.001,
  "task_pair_enc": "simple",
  "task_patience": 5,
  "train_for_eval": 1,
  "train_tasks": "sst",
  "trainer_type": "sampling",
  "val_interval": 10,
  "warmup": 4000,
  "weight_decay": 1e-07,
  "weighting_method": "uniform",
  "word_embs": "glove",
  "word_embs_file": "/usr/share/jsalt/glove/glove.840B.300d.txt",
  "write_preds": 0
}
06/27 03:40:39 PM: Saved config to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst/params.conf
06/27 03:40:39 PM: Using GPU 0
06/27 03:40:39 PM: Using random seed 42
06/27 03:40:39 PM: Loading tasks...
06/27 03:40:39 PM: Writing pre-preprocessed tasks to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/
06/27 03:40:39 PM: 	Loaded existing task sst
06/27 03:40:39 PM: 	Loaded existing task mrpc
06/27 03:40:39 PM: 	Finished loading tasks: sst mrpc.
06/27 03:40:39 PM: 	Building vocab from scratch
06/27 03:40:39 PM: 	Finished counting words
06/27 03:40:39 PM: vocabulary serialization directory /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/vocab is not empty
06/27 03:40:39 PM: 	Saved vocab to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/vocab
06/27 03:40:39 PM: 	Finished building vocab. Using 5002 words, 107 chars.
06/27 03:40:39 PM: 	Building embeddings from scratch
06/27 03:40:48 PM: 	Finished loading embeddings
06/27 03:40:48 PM: 	Saved embeddings to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/embs.pkl
06/27 03:40:48 PM: 	Indexing task sst from scratch
06/27 03:40:56 PM: Your label namespace was 'idxs'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.
06/27 03:40:57 PM: 	Indexing task mrpc from scratch
06/27 03:40:59 PM: 	Finished indexing tasks
06/27 03:41:01 PM: 	Saved data to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/preproc.pkl
06/27 03:41:01 PM: 	  Training on sst
06/27 03:41:01 PM: 	  Evaluating on mrpc
06/27 03:41:01 PM: 	Finished loading tasks in 22.327s
06/27 03:41:01 PM: Building model...
06/27 03:41:01 PM: 	Using word embeddings from /usr/share/jsalt/glove/glove.840B.300d.txt
06/27 03:41:01 PM: 	Not using character embeddings!
06/27 03:41:01 PM: 	Using ELMo character CNN only!
06/27 03:41:06 PM: batch_first = True
06/27 03:41:06 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
06/27 03:41:06 PM: CURRENTLY DEFINED PARAMETERS: 
06/27 03:41:06 PM: input_size = 812
06/27 03:41:06 PM: hidden_size = 128
06/27 03:41:06 PM: num_layers = 1
06/27 03:41:06 PM: bidirectional = 1
06/27 03:41:06 PM: batch_first = True
06/27 03:41:06 PM: Initializing parameters
06/27 03:41:06 PM: Done initializing parameters; the following parameters are using their default initialization from their code
06/27 03:41:06 PM:    _phrase_layer._module.bias_hh_l0
06/27 03:41:06 PM:    _phrase_layer._module.bias_hh_l0_reverse
06/27 03:41:06 PM:    _phrase_layer._module.bias_ih_l0
06/27 03:41:06 PM:    _phrase_layer._module.bias_ih_l0_reverse
06/27 03:41:06 PM:    _phrase_layer._module.weight_hh_l0
06/27 03:41:06 PM:    _phrase_layer._module.weight_hh_l0_reverse
06/27 03:41:06 PM:    _phrase_layer._module.weight_ih_l0
06/27 03:41:06 PM:    _phrase_layer._module.weight_ih_l0_reverse
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo._char_embedding_weights
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo._highways._layers.0.bias
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo._highways._layers.0.weight
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo._highways._layers.1.bias
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo._highways._layers.1.weight
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo._projection.bias
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo._projection.weight
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_0.bias
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_0.weight
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_1.bias
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_1.weight
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_2.bias
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_2.weight
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_3.bias
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_3.weight
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_4.bias
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_4.weight
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_5.bias
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_5.weight
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_6.bias
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_elmo.char_conv_6.weight
06/27 03:41:06 PM:    _text_field_embedder.token_embedder_words.weight
06/27 03:41:10 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BasicTextFieldEmbedder(
      (token_embedder_words): Embedding()
      (token_embedder_elmo): ElmoCharacterEncoder(
        (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
        (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))
        (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))
        (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))
        (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))
        (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))
        (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))
        (_highways): Highway(
          (_layers): ModuleList(
            (0): Linear(in_features=2048, out_features=4096, bias=True)
            (1): Linear(in_features=2048, out_features=4096, bias=True)
          )
        )
        (_projection): Linear(in_features=2048, out_features=512, bias=True)
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): PytorchSeq2SeqWrapper(
      (_module): LSTM(812, 128, batch_first=True, bidirectional=1)
    )
    (_dropout): Dropout(p=0.2)
  )
  (sst_mdl): Sequential(
    (0): Dropout(p=0.2)
    (1): Linear(in_features=1068, out_features=32, bias=True)
    (2): Tanh()
    (3): LayerNorm(torch.Size([32]), eps=1e-05, elementwise_affine=True)
    (4): Dropout(p=0.2)
    (5): Linear(in_features=32, out_features=2, bias=True)
  )
  (pair_encoder): SimplePairEncoder()
  (mrpc_mdl): Sequential(
    (0): Dropout(p=0.2)
    (1): Linear(in_features=4272, out_features=32, bias=True)
    (2): Tanh()
    (3): LayerNorm(torch.Size([32]), eps=1e-05, elementwise_affine=True)
    (4): Dropout(p=0.2)
    (5): Linear(in_features=32, out_features=2, bias=True)
  )
)
06/27 03:41:10 PM: 	Finished building model in 8.769s
06/27 03:41:10 PM: Will run the following steps:
Training model on tasks: sst
Re-training model for individual eval tasks
Evaluating model on tasks: mrpc
06/27 03:41:10 PM: Training...
06/27 03:41:10 PM: patience = 10
06/27 03:41:10 PM: num_epochs = 10000
06/27 03:41:10 PM: max_vals = 10
06/27 03:41:10 PM: cuda_device = 0
06/27 03:41:10 PM: grad_norm = 5.0
06/27 03:41:10 PM: grad_clipping = None
06/27 03:41:10 PM: lr_decay = 0.99
06/27 03:41:10 PM: min_lr = 1e-06
06/27 03:41:10 PM: no_tqdm = 1
06/27 03:41:10 PM: Sampling tasks uniformly
06/27 03:41:10 PM: type = adam
06/27 03:41:10 PM: parameter_groups = None
06/27 03:41:10 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
06/27 03:41:10 PM: CURRENTLY DEFINED PARAMETERS: 
06/27 03:41:10 PM: lr = 0.001
06/27 03:41:10 PM: weight_decay = 1e-05
06/27 03:41:10 PM: amsgrad = True
06/27 03:41:10 PM: type = reduce_on_plateau
06/27 03:41:10 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
06/27 03:41:10 PM: CURRENTLY DEFINED PARAMETERS: 
06/27 03:41:10 PM: mode = max
06/27 03:41:10 PM: factor = 0.5
06/27 03:41:10 PM: patience = 5
06/27 03:41:10 PM: threshold = 0.0001
06/27 03:41:10 PM: threshold_mode = abs
06/27 03:41:10 PM: verbose = True
06/27 03:41:10 PM: type = adam
06/27 03:41:10 PM: parameter_groups = None
06/27 03:41:10 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
06/27 03:41:10 PM: CURRENTLY DEFINED PARAMETERS: 
06/27 03:41:10 PM: lr = 0.001
06/27 03:41:10 PM: weight_decay = 1e-05
06/27 03:41:10 PM: amsgrad = True
06/27 03:41:10 PM: type = reduce_on_plateau
06/27 03:41:10 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
06/27 03:41:10 PM: CURRENTLY DEFINED PARAMETERS: 
06/27 03:41:10 PM: mode = max
06/27 03:41:10 PM: factor = 0.5
06/27 03:41:10 PM: patience = 5
06/27 03:41:10 PM: threshold = 0.0001
06/27 03:41:10 PM: threshold_mode = abs
06/27 03:41:10 PM: verbose = True
06/27 03:41:10 PM: Not loading.
06/27 03:41:10 PM: Beginning training. Stopping metric: sst_accuracy
06/27 03:41:10 PM: ***** Pass 10 / Epoch 1 *****
06/27 03:41:10 PM: sst: trained on 10 batches, 0.002 epochs
06/27 03:41:10 PM: Validating...
06/27 03:41:11 PM: Best model found for sst.
06/27 03:41:11 PM: Best model found for micro.
06/27 03:41:11 PM: Best model found for macro.
06/27 03:41:11 PM: Statistic: sst_loss
06/27 03:41:11 PM: 	training: 0.956259
06/27 03:41:11 PM: 	validation: 0.691696
06/27 03:41:11 PM: Statistic: macro_avg
06/27 03:41:11 PM: 	validation: 0.513761
06/27 03:41:11 PM: Statistic: micro_avg
06/27 03:41:11 PM: 	validation: 0.513761
06/27 03:41:11 PM: Statistic: sst_accuracy
06/27 03:41:11 PM: 	training: 0.456250
06/27 03:41:11 PM: 	validation: 0.513761
06/27 03:41:11 PM: Saved files to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst
06/27 03:41:12 PM: ***** Pass 20 / Epoch 2 *****
06/27 03:41:12 PM: sst: trained on 10 batches, 0.002 epochs
06/27 03:41:12 PM: Validating...
06/27 03:41:13 PM: Statistic: sst_loss
06/27 03:41:13 PM: 	training: 0.691646
06/27 03:41:13 PM: 	validation: 0.693085
06/27 03:41:13 PM: Statistic: macro_avg
06/27 03:41:13 PM: 	validation: 0.509174
06/27 03:41:13 PM: Statistic: micro_avg
06/27 03:41:13 PM: 	validation: 0.509174
06/27 03:41:13 PM: Statistic: sst_accuracy
06/27 03:41:13 PM: 	training: 0.518750
06/27 03:41:13 PM: 	validation: 0.509174
06/27 03:41:13 PM: Saved files to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst
06/27 03:41:13 PM: ***** Pass 30 / Epoch 3 *****
06/27 03:41:13 PM: sst: trained on 10 batches, 0.002 epochs
06/27 03:41:13 PM: Validating...
06/27 03:41:14 PM: Statistic: sst_loss
06/27 03:41:14 PM: 	training: 0.673650
06/27 03:41:14 PM: 	validation: 0.734764
06/27 03:41:14 PM: Statistic: macro_avg
06/27 03:41:14 PM: 	validation: 0.509174
06/27 03:41:14 PM: Statistic: micro_avg
06/27 03:41:14 PM: 	validation: 0.509174
06/27 03:41:14 PM: Statistic: sst_accuracy
06/27 03:41:14 PM: 	training: 0.612500
06/27 03:41:14 PM: 	validation: 0.509174
06/27 03:41:14 PM: Saved files to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst
06/27 03:41:14 PM: ***** Pass 40 / Epoch 4 *****
06/27 03:41:14 PM: sst: trained on 10 batches, 0.002 epochs
06/27 03:41:14 PM: Validating...
06/27 03:41:15 PM: Best model found for sst.
06/27 03:41:15 PM: Best model found for micro.
06/27 03:41:15 PM: Best model found for macro.
06/27 03:41:15 PM: Statistic: sst_loss
06/27 03:41:15 PM: 	training: 0.734866
06/27 03:41:15 PM: 	validation: 0.689672
06/27 03:41:15 PM: Statistic: macro_avg
06/27 03:41:15 PM: 	validation: 0.517202
06/27 03:41:15 PM: Statistic: micro_avg
06/27 03:41:15 PM: 	validation: 0.517202
06/27 03:41:15 PM: Statistic: sst_accuracy
06/27 03:41:15 PM: 	training: 0.525000
06/27 03:41:15 PM: 	validation: 0.517202
06/27 03:41:15 PM: Saved files to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst
06/27 03:41:16 PM: ***** Pass 50 / Epoch 5 *****
06/27 03:41:16 PM: sst: trained on 10 batches, 0.002 epochs
06/27 03:41:16 PM: Validating...
06/27 03:41:17 PM: Statistic: sst_loss
06/27 03:41:17 PM: 	training: 0.711184
06/27 03:41:17 PM: 	validation: 0.692314
06/27 03:41:17 PM: Statistic: macro_avg
06/27 03:41:17 PM: 	validation: 0.509174
06/27 03:41:17 PM: Statistic: micro_avg
06/27 03:41:17 PM: 	validation: 0.509174
06/27 03:41:17 PM: Statistic: sst_accuracy
06/27 03:41:17 PM: 	training: 0.506250
06/27 03:41:17 PM: 	validation: 0.509174
06/27 03:41:17 PM: Saved files to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst
06/27 03:41:17 PM: ***** Pass 60 / Epoch 6 *****
06/27 03:41:17 PM: sst: trained on 10 batches, 0.002 epochs
06/27 03:41:17 PM: Validating...
06/27 03:41:18 PM: Statistic: sst_loss
06/27 03:41:18 PM: 	training: 0.708411
06/27 03:41:18 PM: 	validation: 0.690601
06/27 03:41:18 PM: Statistic: macro_avg
06/27 03:41:18 PM: 	validation: 0.509174
06/27 03:41:18 PM: Statistic: micro_avg
06/27 03:41:18 PM: 	validation: 0.509174
06/27 03:41:18 PM: Statistic: sst_accuracy
06/27 03:41:18 PM: 	training: 0.506250
06/27 03:41:18 PM: 	validation: 0.509174
06/27 03:41:18 PM: Saved files to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst
06/27 03:41:18 PM: ***** Pass 70 / Epoch 7 *****
06/27 03:41:18 PM: sst: trained on 10 batches, 0.002 epochs
06/27 03:41:18 PM: Validating...
06/27 03:41:19 PM: Statistic: sst_loss
06/27 03:41:19 PM: 	training: 0.681091
06/27 03:41:19 PM: 	validation: 0.703903
06/27 03:41:19 PM: Statistic: macro_avg
06/27 03:41:19 PM: 	validation: 0.509174
06/27 03:41:19 PM: Statistic: micro_avg
06/27 03:41:19 PM: 	validation: 0.509174
06/27 03:41:19 PM: Statistic: sst_accuracy
06/27 03:41:19 PM: 	training: 0.593750
06/27 03:41:19 PM: 	validation: 0.509174
06/27 03:41:19 PM: Saved files to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst
06/27 03:41:20 PM: ***** Pass 80 / Epoch 8 *****
06/27 03:41:20 PM: sst: trained on 10 batches, 0.002 epochs
06/27 03:41:20 PM: Validating...
06/27 03:41:20 PM: Batch 5/55: accuracy: 0.4750, sst_loss: 0.7268 ||
06/27 03:41:21 PM: Statistic: sst_loss
06/27 03:41:21 PM: 	training: 0.693834
06/27 03:41:21 PM: 	validation: 0.700242
06/27 03:41:21 PM: Statistic: macro_avg
06/27 03:41:21 PM: 	validation: 0.509174
06/27 03:41:21 PM: Statistic: micro_avg
06/27 03:41:21 PM: 	validation: 0.509174
06/27 03:41:21 PM: Statistic: sst_accuracy
06/27 03:41:21 PM: 	training: 0.543750
06/27 03:41:21 PM: 	validation: 0.509174
06/27 03:41:21 PM: Saved files to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst
06/27 03:41:21 PM: ***** Pass 90 / Epoch 9 *****
06/27 03:41:21 PM: sst: trained on 10 batches, 0.002 epochs
06/27 03:41:21 PM: Validating...
06/27 03:41:22 PM: Statistic: sst_loss
06/27 03:41:22 PM: 	training: 0.683841
06/27 03:41:22 PM: 	validation: 0.687771
06/27 03:41:22 PM: Statistic: macro_avg
06/27 03:41:22 PM: 	validation: 0.509174
06/27 03:41:22 PM: Statistic: micro_avg
06/27 03:41:22 PM: 	validation: 0.509174
06/27 03:41:22 PM: Statistic: sst_accuracy
06/27 03:41:22 PM: 	training: 0.562500
06/27 03:41:22 PM: 	validation: 0.509174
06/27 03:41:22 PM: Saved files to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst
06/27 03:41:22 PM: ***** Pass 100 / Epoch 10 *****
06/27 03:41:22 PM: sst: trained on 10 batches, 0.002 epochs
06/27 03:41:22 PM: Validating...
06/27 03:41:23 PM: Maximum number of validations hit. Stopping training.
06/27 03:41:23 PM: Statistic: sst_loss
06/27 03:41:23 PM: 	training: 0.687257
06/27 03:41:23 PM: 	validation: 0.677646
06/27 03:41:23 PM: Statistic: macro_avg
06/27 03:41:23 PM: 	validation: 0.516055
06/27 03:41:23 PM: Statistic: micro_avg
06/27 03:41:23 PM: 	validation: 0.516055
06/27 03:41:23 PM: Statistic: sst_accuracy
06/27 03:41:23 PM: 	training: 0.568750
06/27 03:41:23 PM: 	validation: 0.516055
06/27 03:41:23 PM: Saved files to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst
06/27 03:41:23 PM: Stopped training after 10 validation checks
06/27 03:41:23 PM: Trained sst for 100 batches or 0.024 epochs
06/27 03:41:23 PM: ***** VALIDATION RESULTS *****
06/27 03:41:23 PM: sst_accuracy, 4, sst_loss: 0.68967, macro_avg: 0.51720, micro_avg: 0.51720, sst_accuracy: 0.51720
06/27 03:41:23 PM: micro_avg, 4, sst_loss: 0.68967, macro_avg: 0.51720, micro_avg: 0.51720, sst_accuracy: 0.51720
06/27 03:41:23 PM: macro_avg, 4, sst_loss: 0.68967, macro_avg: 0.51720, micro_avg: 0.51720, sst_accuracy: 0.51720
06/27 03:41:23 PM: Loaded model state from /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst/model_state_main_epoch_4.best_macro.th
06/27 03:41:23 PM: patience = 10
06/27 03:41:23 PM: num_epochs = 10000
06/27 03:41:23 PM: max_vals = 10
06/27 03:41:23 PM: cuda_device = 0
06/27 03:41:23 PM: grad_norm = 5.0
06/27 03:41:23 PM: grad_clipping = None
06/27 03:41:23 PM: lr_decay = 0.99
06/27 03:41:23 PM: min_lr = 1e-06
06/27 03:41:23 PM: no_tqdm = 1
06/27 03:41:23 PM: Sampling tasks uniformly
06/27 03:41:23 PM: type = adam
06/27 03:41:23 PM: parameter_groups = None
06/27 03:41:23 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
06/27 03:41:23 PM: CURRENTLY DEFINED PARAMETERS: 
06/27 03:41:23 PM: lr = 0.001
06/27 03:41:23 PM: weight_decay = 1e-05
06/27 03:41:23 PM: amsgrad = True
06/27 03:41:23 PM: type = reduce_on_plateau
06/27 03:41:23 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
06/27 03:41:23 PM: CURRENTLY DEFINED PARAMETERS: 
06/27 03:41:23 PM: mode = max
06/27 03:41:23 PM: factor = 0.5
06/27 03:41:23 PM: patience = 5
06/27 03:41:23 PM: threshold = 0.0001
06/27 03:41:23 PM: threshold_mode = abs
06/27 03:41:23 PM: verbose = True
06/27 03:41:23 PM: type = adam
06/27 03:41:23 PM: parameter_groups = None
06/27 03:41:23 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
06/27 03:41:23 PM: CURRENTLY DEFINED PARAMETERS: 
06/27 03:41:23 PM: lr = 0.001
06/27 03:41:23 PM: weight_decay = 1e-05
06/27 03:41:23 PM: amsgrad = True
06/27 03:41:23 PM: type = reduce_on_plateau
06/27 03:41:23 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
06/27 03:41:23 PM: CURRENTLY DEFINED PARAMETERS: 
06/27 03:41:23 PM: mode = max
06/27 03:41:23 PM: factor = 0.5
06/27 03:41:23 PM: patience = 5
06/27 03:41:23 PM: threshold = 0.0001
06/27 03:41:23 PM: threshold_mode = abs
06/27 03:41:23 PM: verbose = True
06/27 03:41:23 PM: Not loading.
06/27 03:41:23 PM: Beginning training. Stopping metric: mrpc_acc_f1
06/27 03:41:24 PM: ***** Pass 10 / Epoch 1 *****
06/27 03:41:24 PM: mrpc: trained on 10 batches, 0.043 epochs
06/27 03:41:24 PM: Validating...
06/27 03:41:25 PM: Best model found for mrpc.
06/27 03:41:25 PM: Best model found for micro.
06/27 03:41:25 PM: Best model found for macro.
06/27 03:41:25 PM: Statistic: mrpc_loss
06/27 03:41:25 PM: 	training: 1.003339
06/27 03:41:25 PM: 	validation: 0.942497
06/27 03:41:25 PM: Statistic: macro_avg
06/27 03:41:25 PM: 	validation: 0.748025
06/27 03:41:25 PM: Statistic: micro_avg
06/27 03:41:25 PM: 	validation: 0.748025
06/27 03:41:25 PM: Statistic: mrpc_acc_f1
06/27 03:41:25 PM: 	training: 0.739756
06/27 03:41:25 PM: 	validation: 0.748025
06/27 03:41:25 PM: Statistic: mrpc_accuracy
06/27 03:41:25 PM: 	training: 0.675000
06/27 03:41:25 PM: 	validation: 0.683824
06/27 03:41:25 PM: Statistic: mrpc_f1
06/27 03:41:25 PM: 	training: 0.804511
06/27 03:41:25 PM: 	validation: 0.812227
06/27 03:41:25 PM: Statistic: mrpc_precision
06/27 03:41:25 PM: 	training: 0.694805
06/27 03:41:25 PM: 	validation: 0.683824
06/27 03:41:25 PM: Statistic: mrpc_recall
06/27 03:41:25 PM: 	training: 0.955357
06/27 03:41:25 PM: 	validation: 1.000000
06/27 03:41:25 PM: Saved files to /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst
06/27 03:41:25 PM: ***** Pass 20 / Epoch 2 *****
06/27 03:41:25 PM: mrpc: trained on 10 batches, 0.043 epochs
06/27 03:41:25 PM: Validating...
06/27 03:41:26 PM: Statistic: mrpc_loss
06/27 03:41:26 PM: 	training: 0.865966
06/27 03:41:26 PM: 	validation: 0.793040
06/27 03:41:26 PM: Statistic: macro_avg
06/27 03:41:26 PM: 	validation: 0.748025
06/27 03:41:26 PM: Statistic: micro_avg
06/27 03:41:26 PM: 	validation: 0.748025
06/27 03:41:26 PM: Statistic: mrpc_acc_f1
06/27 03:41:26 PM: 	training: 0.751157
06/27 03:41:26 PM: 	validation: 0.748025
06/27 03:41:26 PM: Statistic: mrpc_accuracy
06/27 03:41:26 PM: 	training: 0.687500
06/27 03:41:26 PM: 	validation: 0.683824
06/27 03:41:26 PM: Statistic: mrpc_f1
06/27 03:41:26 PM: 	training: 0.814815
06/27 03:41:26 PM: 	validation: 0.812227
06/27 03:41:26 PM: Statistic: mrpc_precision
06/27 03:41:26 PM: 	training: 0.687500
06/27 03:41:26 PM: 	validation: 0.683824
06/27 03:41:26 PM: Statistic: mrpc_recall
06/27 03:41:26 PM: 	training: 1.000000
06/27 03:41:26 PM: 	validation: 1.000000
06/27 03:41:27 PM: ***** Pass 30 / Epoch 3 *****
06/27 03:41:27 PM: mrpc: trained on 10 batches, 0.043 epochs
06/27 03:41:27 PM: Validating...
06/27 03:41:28 PM: Statistic: mrpc_loss
06/27 03:41:28 PM: 	training: 0.722936
06/27 03:41:28 PM: 	validation: 0.696685
06/27 03:41:28 PM: Statistic: macro_avg
06/27 03:41:28 PM: 	validation: 0.748025
06/27 03:41:28 PM: Statistic: micro_avg
06/27 03:41:28 PM: 	validation: 0.748025
06/27 03:41:28 PM: Statistic: mrpc_acc_f1
06/27 03:41:28 PM: 	training: 0.756469
06/27 03:41:28 PM: 	validation: 0.748025
06/27 03:41:28 PM: Statistic: mrpc_accuracy
06/27 03:41:28 PM: 	training: 0.693750
06/27 03:41:28 PM: 	validation: 0.683824
06/27 03:41:28 PM: Statistic: mrpc_f1
06/27 03:41:28 PM: 	training: 0.819188
06/27 03:41:28 PM: 	validation: 0.812227
06/27 03:41:28 PM: Statistic: mrpc_precision
06/27 03:41:28 PM: 	training: 0.693750
06/27 03:41:28 PM: 	validation: 0.683824
06/27 03:41:28 PM: Statistic: mrpc_recall
06/27 03:41:28 PM: 	training: 1.000000
06/27 03:41:28 PM: 	validation: 1.000000
06/27 03:41:28 PM: ***** Pass 40 / Epoch 4 *****
06/27 03:41:28 PM: mrpc: trained on 10 batches, 0.043 epochs
06/27 03:41:28 PM: Validating...
06/27 03:41:29 PM: Statistic: mrpc_loss
06/27 03:41:29 PM: 	training: 0.617764
06/27 03:41:29 PM: 	validation: 0.641783
06/27 03:41:29 PM: Statistic: macro_avg
06/27 03:41:29 PM: 	validation: 0.748025
06/27 03:41:29 PM: Statistic: micro_avg
06/27 03:41:29 PM: 	validation: 0.748025
06/27 03:41:29 PM: Statistic: mrpc_acc_f1
06/27 03:41:29 PM: 	training: 0.777557
06/27 03:41:29 PM: 	validation: 0.748025
06/27 03:41:29 PM: Statistic: mrpc_accuracy
06/27 03:41:29 PM: 	training: 0.718750
06/27 03:41:29 PM: 	validation: 0.683824
06/27 03:41:29 PM: Statistic: mrpc_f1
06/27 03:41:29 PM: 	training: 0.836364
06/27 03:41:29 PM: 	validation: 0.812227
06/27 03:41:29 PM: Statistic: mrpc_precision
06/27 03:41:29 PM: 	training: 0.718750
06/27 03:41:29 PM: 	validation: 0.683824
06/27 03:41:29 PM: Statistic: mrpc_recall
06/27 03:41:29 PM: 	training: 1.000000
06/27 03:41:29 PM: 	validation: 1.000000
06/27 03:41:29 PM: ***** Pass 50 / Epoch 5 *****
06/27 03:41:29 PM: mrpc: trained on 10 batches, 0.043 epochs
06/27 03:41:29 PM: Validating...
06/27 03:41:30 PM: Statistic: mrpc_loss
06/27 03:41:30 PM: 	training: 0.683915
06/27 03:41:30 PM: 	validation: 0.627712
06/27 03:41:30 PM: Statistic: macro_avg
06/27 03:41:30 PM: 	validation: 0.748025
06/27 03:41:30 PM: Statistic: micro_avg
06/27 03:41:30 PM: 	validation: 0.748025
06/27 03:41:30 PM: Statistic: mrpc_acc_f1
06/27 03:41:30 PM: 	training: 0.713510
06/27 03:41:30 PM: 	validation: 0.748025
06/27 03:41:30 PM: Statistic: mrpc_accuracy
06/27 03:41:30 PM: 	training: 0.643750
06/27 03:41:30 PM: 	validation: 0.683824
06/27 03:41:30 PM: Statistic: mrpc_f1
06/27 03:41:30 PM: 	training: 0.783270
06/27 03:41:30 PM: 	validation: 0.812227
06/27 03:41:30 PM: Statistic: mrpc_precision
06/27 03:41:30 PM: 	training: 0.643750
06/27 03:41:30 PM: 	validation: 0.683824
06/27 03:41:30 PM: Statistic: mrpc_recall
06/27 03:41:30 PM: 	training: 1.000000
06/27 03:41:30 PM: 	validation: 1.000000
06/27 03:41:31 PM: ***** Pass 60 / Epoch 6 *****
06/27 03:41:31 PM: mrpc: trained on 10 batches, 0.043 epochs
06/27 03:41:31 PM: Validating...
06/27 03:41:31 PM: Statistic: mrpc_loss
06/27 03:41:31 PM: 	training: 0.635036
06/27 03:41:31 PM: 	validation: 0.622321
06/27 03:41:31 PM: Statistic: macro_avg
06/27 03:41:31 PM: 	validation: 0.748025
06/27 03:41:31 PM: Statistic: micro_avg
06/27 03:41:31 PM: 	validation: 0.748025
06/27 03:41:31 PM: Statistic: mrpc_acc_f1
06/27 03:41:31 PM: 	training: 0.735124
06/27 03:41:31 PM: 	validation: 0.748025
06/27 03:41:31 PM: Statistic: mrpc_accuracy
06/27 03:41:31 PM: 	training: 0.668750
06/27 03:41:31 PM: 	validation: 0.683824
06/27 03:41:31 PM: Statistic: mrpc_f1
06/27 03:41:31 PM: 	training: 0.801498
06/27 03:41:31 PM: 	validation: 0.812227
06/27 03:41:31 PM: Statistic: mrpc_precision
06/27 03:41:31 PM: 	training: 0.668750
06/27 03:41:31 PM: 	validation: 0.683824
06/27 03:41:31 PM: Statistic: mrpc_recall
06/27 03:41:31 PM: 	training: 1.000000
06/27 03:41:31 PM: 	validation: 1.000000
06/27 03:41:32 PM: ***** Pass 70 / Epoch 7 *****
06/27 03:41:32 PM: mrpc: trained on 10 batches, 0.043 epochs
06/27 03:41:32 PM: Validating...
06/27 03:41:33 PM: Statistic: mrpc_loss
06/27 03:41:33 PM: 	training: 0.633888
06/27 03:41:33 PM: 	validation: 0.624909
06/27 03:41:33 PM: Statistic: macro_avg
06/27 03:41:33 PM: 	validation: 0.748025
06/27 03:41:33 PM: Statistic: micro_avg
06/27 03:41:33 PM: 	validation: 0.748025
06/27 03:41:33 PM: Statistic: mrpc_acc_f1
06/27 03:41:33 PM: 	training: 0.728977
06/27 03:41:33 PM: 	validation: 0.748025
06/27 03:41:33 PM: Statistic: mrpc_accuracy
06/27 03:41:33 PM: 	training: 0.662500
06/27 03:41:33 PM: 	validation: 0.683824
06/27 03:41:33 PM: Statistic: mrpc_f1
06/27 03:41:33 PM: 	training: 0.795455
06/27 03:41:33 PM: 	validation: 0.812227
06/27 03:41:33 PM: Statistic: mrpc_precision
06/27 03:41:33 PM: 	training: 0.664557
06/27 03:41:33 PM: 	validation: 0.683824
06/27 03:41:33 PM: Statistic: mrpc_recall
06/27 03:41:33 PM: 	training: 0.990566
06/27 03:41:33 PM: 	validation: 1.000000
06/27 03:41:33 PM: ***** Pass 80 / Epoch 8 *****
06/27 03:41:33 PM: mrpc: trained on 10 batches, 0.043 epochs
06/27 03:41:33 PM: Validating...
06/27 03:41:33 PM: Batch 10/26: acc_f1: 0.7828, accuracy: 0.7250, f1: 0.8406, precision: 0.7250, recall: 1.0000, mrpc_loss: 0.5981 ||
06/27 03:41:34 PM: Statistic: mrpc_loss
06/27 03:41:34 PM: 	training: 0.622750
06/27 03:41:34 PM: 	validation: 0.627621
06/27 03:41:34 PM: Statistic: macro_avg
06/27 03:41:34 PM: 	validation: 0.748025
06/27 03:41:34 PM: Statistic: micro_avg
06/27 03:41:34 PM: 	validation: 0.748025
06/27 03:41:34 PM: Statistic: mrpc_acc_f1
06/27 03:41:34 PM: 	training: 0.756469
06/27 03:41:34 PM: 	validation: 0.748025
06/27 03:41:34 PM: Statistic: mrpc_accuracy
06/27 03:41:34 PM: 	training: 0.693750
06/27 03:41:34 PM: 	validation: 0.683824
06/27 03:41:34 PM: Statistic: mrpc_f1
06/27 03:41:34 PM: 	training: 0.819188
06/27 03:41:34 PM: 	validation: 0.812227
06/27 03:41:34 PM: Statistic: mrpc_precision
06/27 03:41:34 PM: 	training: 0.698113
06/27 03:41:34 PM: 	validation: 0.683824
06/27 03:41:34 PM: Statistic: mrpc_recall
06/27 03:41:34 PM: 	training: 0.991071
06/27 03:41:34 PM: 	validation: 1.000000
06/27 03:41:34 PM: ***** Pass 90 / Epoch 9 *****
06/27 03:41:34 PM: mrpc: trained on 10 batches, 0.043 epochs
06/27 03:41:34 PM: Validating...
06/27 03:41:35 PM: Statistic: mrpc_loss
06/27 03:41:35 PM: 	training: 0.642283
06/27 03:41:35 PM: 	validation: 0.624996
06/27 03:41:35 PM: Statistic: macro_avg
06/27 03:41:35 PM: 	validation: 0.748025
06/27 03:41:35 PM: Statistic: micro_avg
06/27 03:41:35 PM: 	validation: 0.748025
06/27 03:41:35 PM: Statistic: mrpc_acc_f1
06/27 03:41:35 PM: 	training: 0.729746
06/27 03:41:35 PM: 	validation: 0.748025
06/27 03:41:35 PM: Statistic: mrpc_accuracy
06/27 03:41:35 PM: 	training: 0.662500
06/27 03:41:35 PM: 	validation: 0.683824
06/27 03:41:35 PM: Statistic: mrpc_f1
06/27 03:41:35 PM: 	training: 0.796992
06/27 03:41:35 PM: 	validation: 0.812227
06/27 03:41:35 PM: Statistic: mrpc_precision
06/27 03:41:35 PM: 	training: 0.662500
06/27 03:41:35 PM: 	validation: 0.683824
06/27 03:41:35 PM: Statistic: mrpc_recall
06/27 03:41:35 PM: 	training: 1.000000
06/27 03:41:35 PM: 	validation: 1.000000
06/27 03:41:36 PM: ***** Pass 100 / Epoch 10 *****
06/27 03:41:36 PM: mrpc: trained on 10 batches, 0.043 epochs
06/27 03:41:36 PM: Validating...
06/27 03:41:37 PM: Maximum number of validations hit. Stopping training.
06/27 03:41:37 PM: Statistic: mrpc_loss
06/27 03:41:37 PM: 	training: 0.645101
06/27 03:41:37 PM: 	validation: 0.625257
06/27 03:41:37 PM: Statistic: macro_avg
06/27 03:41:37 PM: 	validation: 0.748025
06/27 03:41:37 PM: Statistic: micro_avg
06/27 03:41:37 PM: 	validation: 0.748025
06/27 03:41:37 PM: Statistic: mrpc_acc_f1
06/27 03:41:37 PM: 	training: 0.735124
06/27 03:41:37 PM: 	validation: 0.748025
06/27 03:41:37 PM: Statistic: mrpc_accuracy
06/27 03:41:37 PM: 	training: 0.668750
06/27 03:41:37 PM: 	validation: 0.683824
06/27 03:41:37 PM: Statistic: mrpc_f1
06/27 03:41:37 PM: 	training: 0.801498
06/27 03:41:37 PM: 	validation: 0.812227
06/27 03:41:37 PM: Statistic: mrpc_precision
06/27 03:41:37 PM: 	training: 0.668750
06/27 03:41:37 PM: 	validation: 0.683824
06/27 03:41:37 PM: Statistic: mrpc_recall
06/27 03:41:37 PM: 	training: 1.000000
06/27 03:41:37 PM: 	validation: 1.000000
06/27 03:41:37 PM: Stopped training after 10 validation checks
06/27 03:41:37 PM: Trained mrpc for 100 batches or 0.435 epochs
06/27 03:41:37 PM: ***** VALIDATION RESULTS *****
06/27 03:41:37 PM: mrpc_acc_f1, 1, mrpc_loss: 0.94250, macro_avg: 0.74803, micro_avg: 0.74803, mrpc_acc_f1: 0.74803, mrpc_accuracy: 0.68382, mrpc_f1: 0.81223, mrpc_precision: 0.68382, mrpc_recall: 1.00000
06/27 03:41:37 PM: micro_avg, 1, mrpc_loss: 0.94250, macro_avg: 0.74803, micro_avg: 0.74803, mrpc_acc_f1: 0.74803, mrpc_accuracy: 0.68382, mrpc_f1: 0.81223, mrpc_precision: 0.68382, mrpc_recall: 1.00000
06/27 03:41:37 PM: macro_avg, 1, mrpc_loss: 0.94250, macro_avg: 0.74803, micro_avg: 0.74803, mrpc_acc_f1: 0.74803, mrpc_accuracy: 0.68382, mrpc_f1: 0.81223, mrpc_precision: 0.68382, mrpc_recall: 1.00000
06/27 03:41:37 PM: Loaded model state from /home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst/model_state_eval_best.th
06/27 03:41:37 PM: Evaluating...
06/27 03:41:39 PM: micro_accuracy: 0.591, macro_accuracy: 0.633, sst_accuracy: 0.517, mrpc_acc_f1: 0.748, mrpc_accuracy: 0.684, mrpc_f1: 0.812, mrpc_precision: 0.684, mrpc_recall: 1.000
06/27 03:41:39 PM: Done!
/home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst/model_state_main_epoch_1.best_macro.th
/home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst/metric_state_main_epoch_1.best_macro.th
/home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst/task_state_main_epoch_1.best_macro.th
/home/raghu1991_p_gmail_com/exp/jiant-demo_v3/sst/training_state_main_epoch_1.best_macro.th
