include "../defaults.conf"
exp_name = "taskmaster"


// Eval will use task-specific params.
do_pretrain = 0        // skip main train phase
allow_untrained_encoder_parameters = 1  // allow skipping training phase
allow_missing_task_map = 1  // ignore missing classifier_task_map.json
do_target_task_training = 1  // train using eval task params
do_full_eval = 1
write_preds = "val,test"
transfer_paradigm = finetune
lr_patience = 5  // vals until LR decay
patience = 20      // vals until early-stopping
lr = .00001
min_lr = .0000001
batch_size = 4
input_module = "roberta-large"
tokenizer = "roberta-large"
max_seq_len = 512
cove = 0
// Use no-op encoder (no params).
sent_enc = "none"
skip_embs = 1  // forward embeddings from lower level.
sep_embs_for_skip = 1  // use task embeddings since we skip the generic ones.
span_classifier_loss_fn = "sigmoid"

